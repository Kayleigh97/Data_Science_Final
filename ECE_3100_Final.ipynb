{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 3100 Fall 2018 - Final Exam\n",
    "## Kayleigh James\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import scipy.io\n",
    "\n",
    "mat = scipy.io.loadmat('ex1.mat') #load in MATLAB data\n",
    "df = pd.DataFrame(np.hstack((mat['x'], mat['y']))) #convert to pandas dataframe\n",
    "\n",
    "X = df.loc[:,0]\n",
    "y = df.loc[:,1] \n",
    "\n",
    "X2 = X.pow(2)\n",
    "X3 = X.pow(3)\n",
    "X4 = X.pow(4)\n",
    "X5 = X.pow(5)\n",
    "X6 = X.pow(6)\n",
    "X7 = X.pow(7)\n",
    "X8 = X.pow(8)\n",
    "X9 = X.pow(9)\n",
    "X10 = X.pow(10)\n",
    "#add all polynomial terms\n",
    "X = pd.concat([X, X2, X3, X4, X5, X6, X7, X8, X9, X10], axis=1, sort=False)\n",
    "#normalize to mean=0, std dev=1\n",
    "X = (X - X.mean())/X.std()\n",
    "#split 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "def mse_cv(model):\n",
    "    mse= -cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    return(mse)\n",
    "def mse_cv2(model):\n",
    "    mse= -cross_val_score(model, X_test, y_test, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    return(mse)\n",
    "model_ridge = Ridge()\n",
    "alphas = np.linspace(0,6,num=601)\n",
    "cv_ridge = [mse_cv(Ridge(alpha = i)).mean() \n",
    "            for i in alphas]\n",
    "cv_ridge2 = [mse_cv2(Ridge(alpha = i)).mean() \n",
    "            for i in alphas]\n",
    "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
    "cv_ridge2 = pd.Series(cv_ridge2, index = alphas)\n",
    "plt.figure()\n",
    "cv_ridge.plot(title = \"Choosing Lambda\",label='Train')\n",
    "cv_ridge2.plot(title = \"Choosing Lambda\",label='Test')\n",
    "\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.xlim(left=0.1, right=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.3623</td>\n",
       "      <td>5.2098</td>\n",
       "      <td>5.4737</td>\n",
       "      <td>6.6263</td>\n",
       "      <td>9.9236</td>\n",
       "      <td>18.4619</td>\n",
       "      <td>14.8866</td>\n",
       "      <td>9.0737</td>\n",
       "      <td>7.0913</td>\n",
       "      <td>6.6193</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3381</td>\n",
       "      <td>1.3653</td>\n",
       "      <td>1.3287</td>\n",
       "      <td>1.2811</td>\n",
       "      <td>1.2763</td>\n",
       "      <td>1.3169</td>\n",
       "      <td>1.3483</td>\n",
       "      <td>1.3107</td>\n",
       "      <td>1.2368</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9433</td>\n",
       "      <td>5.0977</td>\n",
       "      <td>5.4833</td>\n",
       "      <td>6.4282</td>\n",
       "      <td>8.9200</td>\n",
       "      <td>17.1025</td>\n",
       "      <td>19.1354</td>\n",
       "      <td>9.4207</td>\n",
       "      <td>6.7783</td>\n",
       "      <td>6.3983</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6321</td>\n",
       "      <td>1.4852</td>\n",
       "      <td>1.4735</td>\n",
       "      <td>1.5740</td>\n",
       "      <td>1.6437</td>\n",
       "      <td>1.5194</td>\n",
       "      <td>1.3163</td>\n",
       "      <td>1.1748</td>\n",
       "      <td>1.1029</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.5902</td>\n",
       "      <td>5.2543</td>\n",
       "      <td>6.6932</td>\n",
       "      <td>9.8117</td>\n",
       "      <td>17.3004</td>\n",
       "      <td>25.8255</td>\n",
       "      <td>18.0681</td>\n",
       "      <td>13.4678</td>\n",
       "      <td>11.9157</td>\n",
       "      <td>11.7887</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4969</td>\n",
       "      <td>1.5541</td>\n",
       "      <td>1.5478</td>\n",
       "      <td>1.4590</td>\n",
       "      <td>1.3808</td>\n",
       "      <td>1.3799</td>\n",
       "      <td>1.4600</td>\n",
       "      <td>1.5504</td>\n",
       "      <td>1.5209</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.6043</td>\n",
       "      <td>11.5151</td>\n",
       "      <td>11.8183</td>\n",
       "      <td>14.7271</td>\n",
       "      <td>24.3701</td>\n",
       "      <td>37.5369</td>\n",
       "      <td>21.2592</td>\n",
       "      <td>14.8966</td>\n",
       "      <td>13.5028</td>\n",
       "      <td>14.7867</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1933</td>\n",
       "      <td>1.2063</td>\n",
       "      <td>1.2619</td>\n",
       "      <td>1.3244</td>\n",
       "      <td>1.3348</td>\n",
       "      <td>1.2928</td>\n",
       "      <td>1.2713</td>\n",
       "      <td>1.3387</td>\n",
       "      <td>1.5438</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.5607</td>\n",
       "      <td>25.9883</td>\n",
       "      <td>35.9847</td>\n",
       "      <td>46.7400</td>\n",
       "      <td>38.2484</td>\n",
       "      <td>29.5141</td>\n",
       "      <td>26.3746</td>\n",
       "      <td>25.7441</td>\n",
       "      <td>24.6300</td>\n",
       "      <td>22.6506</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4635</td>\n",
       "      <td>1.3889</td>\n",
       "      <td>1.3834</td>\n",
       "      <td>1.4727</td>\n",
       "      <td>1.5947</td>\n",
       "      <td>1.6398</td>\n",
       "      <td>1.6309</td>\n",
       "      <td>1.6936</td>\n",
       "      <td>1.8663</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2        3        4        5        6        7    \\\n",
       "0   5.3623   5.2098   5.4737   6.6263   9.9236  18.4619  14.8866   9.0737   \n",
       "1   4.9433   5.0977   5.4833   6.4282   8.9200  17.1025  19.1354   9.4207   \n",
       "2   4.5902   5.2543   6.6932   9.8117  17.3004  25.8255  18.0681  13.4678   \n",
       "3  12.6043  11.5151  11.8183  14.7271  24.3701  37.5369  21.2592  14.8966   \n",
       "4  21.5607  25.9883  35.9847  46.7400  38.2484  29.5141  26.3746  25.7441   \n",
       "\n",
       "       8        9   ...      131     132     133     134     135     136  \\\n",
       "0   7.0913   6.6193 ...   1.3381  1.3653  1.3287  1.2811  1.2763  1.3169   \n",
       "1   6.7783   6.3983 ...   1.6321  1.4852  1.4735  1.5740  1.6437  1.5194   \n",
       "2  11.9157  11.7887 ...   1.4969  1.5541  1.5478  1.4590  1.3808  1.3799   \n",
       "3  13.5028  14.7867 ...   1.1933  1.2063  1.2619  1.3244  1.3348  1.2928   \n",
       "4  24.6300  22.6506 ...   1.4635  1.3889  1.3834  1.4727  1.5947  1.6398   \n",
       "\n",
       "      137     138     139  140  \n",
       "0  1.3483  1.3107  1.2368  1.0  \n",
       "1  1.3163  1.1748  1.1029  1.0  \n",
       "2  1.4600  1.5504  1.5209  1.0  \n",
       "3  1.2713  1.3387  1.5438  1.0  \n",
       "4  1.6309  1.6936  1.8663  2.0  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "mat = scipy.io.loadmat('ex2.mat') #load in MATLAB data\n",
    "df = pd.DataFrame(np.hstack((mat['features'], mat['responses']))) #convert to pandas dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True) #shuffle the dataset each time\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,0:139] #140 columns are features\n",
    "y = df.loc[:,140] #one column of response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to binary classification\n",
    "y = y.replace(to_replace=1, value=0) #class 1 to negative class\n",
    "y = y.replace(to_replace=2, value=0) #class 2 to negative class\n",
    "y = y.replace(to_replace=3, value=1) #class 3 to positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "... X, y, test_size=0.40, random_state=42) #split to 60% train, rest for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train: 0.969697 \n",
      "\n",
      "Accuracy of Test: 1.000000 \n",
      "\n",
      "Train Precision, Recall, & F1 Score\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97        19\n",
      "        1.0       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.97      0.97      0.97        33\n",
      "\n",
      "Test Precision, Recall, & F1 Score\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00        14\n",
      "        1.0       1.00      1.00      1.00         8\n",
      "\n",
      "avg / total       1.00      1.00      1.00        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train Naive Bayes Classifier\n",
    "gnb = GaussianNB()\n",
    "y_pred_train = gnb.fit(X_train, y_train).predict(X_train) #use to predict train\n",
    "y_pred_test = gnb.fit(X_train, y_train).predict(X_test) #use to predict test\n",
    "\n",
    "class_report_train = classification_report(y_train, y_pred_train) #train f1, prec, recall\n",
    "class_report_test = classification_report(y_test, y_pred_test) #test f1, prec, recall\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train) #train accuracy\n",
    "acc_test = accuracy_score(y_test, y_pred_test) #test accuracy\n",
    "\n",
    "print(\"Accuracy of Train: %f \\n\" % (acc_train))\n",
    "print(\"Accuracy of Test: %f \\n\" % (acc_test))\n",
    "\n",
    "print(\"Train Precision, Recall, & F1 Score\\n\")\n",
    "print(class_report_train)\n",
    "\n",
    "print(\"Test Precision, Recall, & F1 Score\\n\")\n",
    "print(class_report_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.8156</td>\n",
       "      <td>13.4922</td>\n",
       "      <td>15.9691</td>\n",
       "      <td>12.6912</td>\n",
       "      <td>8.8040</td>\n",
       "      <td>6.5935</td>\n",
       "      <td>5.4018</td>\n",
       "      <td>4.8169</td>\n",
       "      <td>4.6914</td>\n",
       "      <td>5.0303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0868</td>\n",
       "      <td>1.0683</td>\n",
       "      <td>1.0988</td>\n",
       "      <td>1.1577</td>\n",
       "      <td>1.2207</td>\n",
       "      <td>1.2881</td>\n",
       "      <td>1.3854</td>\n",
       "      <td>1.5141</td>\n",
       "      <td>1.5877</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5076</td>\n",
       "      <td>12.7375</td>\n",
       "      <td>15.2584</td>\n",
       "      <td>20.2873</td>\n",
       "      <td>31.0176</td>\n",
       "      <td>46.1783</td>\n",
       "      <td>36.6476</td>\n",
       "      <td>25.9575</td>\n",
       "      <td>21.6559</td>\n",
       "      <td>20.5218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2938</td>\n",
       "      <td>1.1665</td>\n",
       "      <td>1.0918</td>\n",
       "      <td>1.0862</td>\n",
       "      <td>1.1447</td>\n",
       "      <td>1.2503</td>\n",
       "      <td>1.3521</td>\n",
       "      <td>1.3697</td>\n",
       "      <td>1.2877</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.6566</td>\n",
       "      <td>12.4529</td>\n",
       "      <td>9.5947</td>\n",
       "      <td>6.2945</td>\n",
       "      <td>5.0388</td>\n",
       "      <td>4.8899</td>\n",
       "      <td>5.6474</td>\n",
       "      <td>7.6126</td>\n",
       "      <td>10.4605</td>\n",
       "      <td>10.4744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2804</td>\n",
       "      <td>1.2279</td>\n",
       "      <td>1.1898</td>\n",
       "      <td>1.1791</td>\n",
       "      <td>1.1773</td>\n",
       "      <td>1.1758</td>\n",
       "      <td>1.2022</td>\n",
       "      <td>1.2932</td>\n",
       "      <td>1.4294</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2        3        4        5        6        7    \\\n",
       "0  10.8156  13.4922  15.9691  12.6912   8.8040   6.5935   5.4018   4.8169   \n",
       "1  11.5076  12.7375  15.2584  20.2873  31.0176  46.1783  36.6476  25.9575   \n",
       "2   9.6566  12.4529   9.5947   6.2945   5.0388   4.8899   5.6474   7.6126   \n",
       "\n",
       "       8        9   ...      131     132     133     134     135     136  \\\n",
       "0   4.6914   5.0303 ...   1.0868  1.0683  1.0988  1.1577  1.2207  1.2881   \n",
       "1  21.6559  20.5218 ...   1.2938  1.1665  1.0918  1.0862  1.1447  1.2503   \n",
       "2  10.4605  10.4744 ...   1.2804  1.2279  1.1898  1.1791  1.1773  1.1758   \n",
       "\n",
       "      137     138     139  140  \n",
       "0  1.3854  1.5141  1.5877  2.0  \n",
       "1  1.3521  1.3697  1.2877  1.0  \n",
       "2  1.2022  1.2932  1.4294  2.0  \n",
       "\n",
       "[3 rows x 141 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.hstack((mat['points'], mat['expected']))) #convert to pandas dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True) #shuffle the dataset each time\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use expected and points from the file\n",
    "points = df.loc[:,0:139] #140 columns are features\n",
    "expected = df.loc[:,140] #one column of response\n",
    "expected = expected.replace(to_replace=1, value=0) #class 1 to negative class\n",
    "expected = expected.replace(to_replace=2, value=0) #class 2 to negative class\n",
    "expected = expected.replace(to_replace=3, value=1) #class 3 to positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Points/Expected: 0.666667 \n",
      "\n",
      "Misclassification Error for Points/Expected: 0.333333 \n",
      "\n",
      "Expected Set Precision, Recall, & F1 Score\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.67      0.80         3\n",
      "        1.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.67      0.80         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jamesmk\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "expected_pred = gnb.fit(X_train, y_train).predict(points) #use to predict expected\n",
    "miss_err = 1 - accuracy_score(expected, expected_pred) #misclassification error\n",
    "acc_exp = accuracy_score(expected, expected_pred) #test accuracy\n",
    "class_report_exp = classification_report(expected, expected_pred)\n",
    "print(\"Accuracy of Points/Expected: %f \\n\" % (acc_exp))\n",
    "print(\"Misclassification Error for Points/Expected: %f \\n\" % (miss_err))\n",
    "print(\"Expected Set Precision, Recall, & F1 Score\\n\")\n",
    "print(class_report_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 zero coefficients\n",
      "139 non-zero coefficients\n"
     ]
    }
   ],
   "source": [
    "mat = scipy.io.loadmat('ex2.mat') #load in MATLAB data\n",
    "df = pd.DataFrame(np.hstack((mat['features'], mat['responses']))) #convert to pandas dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True) #shuffle the dataset each time\n",
    "#train elastic net\n",
    "X_train, y_train = make_regression(n_features=140, random_state=0)\n",
    "l1_reg = 0.01 / .2 #l1 ratio (needed for sklearn implementation) is lambda/alhpa \n",
    "regr = ElasticNetCV(l1_ratio=l1_reg)\n",
    "regr.fit(X_train, y_train)\n",
    "coefs = regr.coef_ #capture the returned coefficients \n",
    "print(sum(coefs==0),'zero coefficients')\n",
    "print(sum(coefs!=0),'non-zero coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n"
     ]
    }
   ],
   "source": [
    "indexArray = [i for i, x in enumerate(coefs) if x]\n",
    "print(indexArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,140] #one column of response\n",
    "X = df.loc[:,indexArray] #only columns with non-zero coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace(to_replace=1, value=0) #class 1 to negative class\n",
    "y = y.replace(to_replace=2, value=0) #class 2 to negative class\n",
    "y = y.replace(to_replace=3, value=1) #class 3 to positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "... X, y, test_size=0.40, random_state=42) #split to 60% train, rest for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train: 1.000000 \n",
      "\n",
      "Accuracy of Test: 0.954545 \n",
      "\n",
      "Train Precision, Recall, & F1 Score\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00        18\n",
      "        1.0       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        33\n",
      "\n",
      "Test Precision, Recall, & F1 Score\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97        15\n",
      "        1.0       1.00      0.86      0.92         7\n",
      "\n",
      "avg / total       0.96      0.95      0.95        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#re-do all of the before stuff with unnecessary features removed\n",
    "gnb = GaussianNB()\n",
    "y_pred_train = gnb.fit(X_train, y_train).predict(X_train) #use to predict train\n",
    "y_pred_test = gnb.fit(X_train, y_train).predict(X_test) #use to predict test\n",
    "\n",
    "class_report_train = classification_report(y_train, y_pred_train) #train f1, prec, recall\n",
    "class_report_test = classification_report(y_test, y_pred_test) #test f1, prec, recall\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train) #train accuracy\n",
    "acc_test = accuracy_score(y_test, y_pred_test) #test accuracy\n",
    "\n",
    "print(\"Accuracy of Train: %f \\n\" % (acc_train))\n",
    "print(\"Accuracy of Test: %f \\n\" % (acc_test))\n",
    "\n",
    "print(\"Train Precision, Recall, & F1 Score\\n\")\n",
    "print(class_report_train)\n",
    "\n",
    "print(\"Test Precision, Recall, & F1 Score\\n\")\n",
    "print(class_report_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Points/Expected: 0.981818 \n",
      "\n",
      "Misclassification Error for Points/Expected: 0.018182 \n",
      "\n",
      "Expected Set Precision, Recall, & F1 Score\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99        33\n",
      "        1.0       1.00      0.95      0.98        22\n",
      "\n",
      "avg / total       0.98      0.98      0.98        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "points = df.loc[:,indexArray] #140 columns are features\n",
    "expected = df.loc[:,140] #one column of response\n",
    "expected = expected.replace(to_replace=1, value=0) #class 1 to negative class\n",
    "expected = expected.replace(to_replace=2, value=0) #class 2 to negative class\n",
    "expected = expected.replace(to_replace=3, value=1) #class 3 to positive class\n",
    "expected_pred = gnb.fit(X_train, y_train).predict(points) #use to predict expected\n",
    "miss_err = 1 - accuracy_score(expected, expected_pred) #misclassification error\n",
    "acc_exp = accuracy_score(expected, expected_pred) #test accuracy\n",
    "class_report_exp = classification_report(expected, expected_pred)\n",
    "print(\"Accuracy of Points/Expected: %f \\n\" % (acc_exp))\n",
    "print(\"Misclassification Error for Points/Expected: %f \\n\" % (miss_err))\n",
    "print(\"Expected Set Precision, Recall, & F1 Score\\n\")\n",
    "print(class_report_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running my code several times, I noticed that the metrics would fluctuate several percent due to taking different data in the test and train sets (since we shuffle each time the code is run).  Additionally, prior to removing the unnecessary features with the elastic net, running the model on the expected/points data set didn't yield good metrics.  However, after the removal of the unnecessary features, the model performed very well for the expected/points data set.  Using an elastic net helps us to decide which features we should remove or keep to improve the accuracy and other metrics of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
